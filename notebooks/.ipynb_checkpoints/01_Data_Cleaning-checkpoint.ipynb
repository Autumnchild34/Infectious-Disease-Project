{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c815ab-fe2a-4eb8-8ace-1a4257b8d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (141777, 10)\n",
      "Columns: ['Disease', 'County', 'Year', 'Sex', 'Count', 'Population', 'Rate', 'CI.lower', 'CI.upper', 'Unstable']\n",
      "\n",
      "==================================================\n",
      "\n",
      "1. INITIAL DATA INSPECTION\n",
      "==============================\n",
      "Data Types:\n",
      "Disease        object\n",
      "County         object\n",
      "Year            int64\n",
      "Sex            object\n",
      "Count           int64\n",
      "Population      int64\n",
      "Rate          float64\n",
      "CI.lower      float64\n",
      "CI.upper      float64\n",
      "Unstable       object\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "     Disease      County  Year     Sex  Count  Population   Rate  CI.lower  \\\n",
      "0  Amebiasis  California  2001   Total    571    34514777  1.654     1.521   \n",
      "1  Amebiasis  California  2001  Female    176    17340743  1.015     0.871   \n",
      "2  Amebiasis  California  2001    Male    365    17174034  2.125     1.913   \n",
      "3  Amebiasis  California  2002   Total    442    34940334  1.265     1.150   \n",
      "4  Amebiasis  California  2002  Female    145    17555714  0.826     0.697   \n",
      "\n",
      "   CI.upper Unstable  \n",
      "0     1.796           \n",
      "1     1.176           \n",
      "2     2.355           \n",
      "3     1.389           \n",
      "4     0.972           \n",
      "\n",
      "Last 5 rows:\n",
      "            Disease County  Year     Sex  Count  Population  Rate  CI.lower  \\\n",
      "141772  Yersiniosis   Yuba  2013  Female      0       36296   0.0       0.0   \n",
      "141773  Yersiniosis   Yuba  2013    Male      0       36698   0.0       0.0   \n",
      "141774  Yersiniosis   Yuba  2014   Total      0       73425   0.0       0.0   \n",
      "141775  Yersiniosis   Yuba  2014  Female      0       36503   0.0       0.0   \n",
      "141776  Yersiniosis   Yuba  2014    Male      0       36922   0.0       0.0   \n",
      "\n",
      "        CI.upper Unstable  \n",
      "141772    10.163        -  \n",
      "141773    10.051        -  \n",
      "141774     5.024        -  \n",
      "141775    10.105        -  \n",
      "141776     9.991        -  \n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../data/Infectious Disease 2001-2014.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 1. INITIAL DATA INSPECTION\n",
    "print(\"1. INITIAL DATA INSPECTION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Basic info\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df.tail())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0a22a3-9928-43d7-aac4-f6e4f4759a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. MISSING VALUE ANALYSIS\n",
      "==============================\n",
      "Missing values per column:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 2. MISSING VALUE ANALYSIS\n",
    "print(\"\\n2. MISSING VALUE ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary[missing_summary['Missing Values'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34f7a26-aa59-4bcf-b4a5-d6f306a95640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. DATA TYPE VALIDATION\n",
      "==============================\n",
      "Current data types:\n",
      "Disease        object\n",
      "County         object\n",
      "Year            int64\n",
      "Sex            object\n",
      "Count           int64\n",
      "Population      int64\n",
      "Rate          float64\n",
      "CI.lower      float64\n",
      "CI.upper      float64\n",
      "Unstable       object\n",
      "dtype: object\n",
      "\n",
      "Updated data types:\n",
      "Disease        object\n",
      "County         object\n",
      "Year            int64\n",
      "Sex            object\n",
      "Count           int64\n",
      "Population      int64\n",
      "Rate          float64\n",
      "CI.lower      float64\n",
      "CI.upper      float64\n",
      "Unstable       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3. DATA TYPE VALIDATION AND CORRECTION\n",
    "print(\"\\n3. DATA TYPE VALIDATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Check current dtypes\n",
    "print(\"Current data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert Year to datetime or keep as integer\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "\n",
    "# Ensure numeric columns are properly typed\n",
    "numeric_cols = ['Count', 'Population', 'Rate', 'CI.lower', 'CI.upper']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f8a6c8-0549-497a-9b8d-97a3cdc94ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. UNIQUE VALUE ANALYSIS\n",
      "==============================\n",
      "\n",
      "Disease:\n",
      "  Unique values: 65\n",
      "  Sample: ['Amebiasis' 'Anaplasmosis and Ehrlichiosis' 'Babesiosis' 'Cholera'\n",
      " 'Botulism, Other' 'Botulism, Foodborne' 'Botulism, Wound' 'Brucellosis'\n",
      " 'Campylobacteriosis' 'Chlamydia']\n",
      "\n",
      "County:\n",
      "  Unique values: 59\n",
      "  Sample: ['California' 'Alameda' 'Alpine' 'Amador' 'Butte' 'Calaveras' 'Colusa'\n",
      " 'Contra Costa' 'Del Norte' 'El Dorado']\n",
      "\n",
      "Year:\n",
      "  Unique values: 14\n",
      "  Sample: [2001 2002 2003 2004 2005 2006 2007 2008 2009 2010]\n",
      "  All values: [2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014]\n",
      "\n",
      "Sex:\n",
      "  Unique values: 3\n",
      "  Sample: ['Total' 'Female' 'Male']\n",
      "  All values: ['Total' 'Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "# 4. UNIQUE VALUE ANALYSIS\n",
    "print(\"\\n4. UNIQUE VALUE ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for column in ['Disease', 'County', 'Year', 'Sex']:\n",
    "    unique_vals = df[column].unique()\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"  Unique values: {len(unique_vals)}\")\n",
    "    print(f\"  Sample: {unique_vals[:10]}\")\n",
    "    if len(unique_vals) < 20:\n",
    "        print(f\"  All values: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff92d8d9-c8fa-4427-8ace-760b23f4f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. DATA CONSISTENCY CHECKS\n",
      "==============================\n",
      "Rows with inconsistent rate calculation: 56\n",
      "Rows with CI bounds inconsistent with Rate: 0\n"
     ]
    }
   ],
   "source": [
    "# 5. CONSISTENCY CHECKS\n",
    "print(\"\\n5. DATA CONSISTENCY CHECKS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Check if Rate calculation matches Count/Population\n",
    "df['Calculated_Rate'] = (df['Count'] / df['Population']) * 100000\n",
    "df['Rate_Diff'] = abs(df['Rate'] - df['Calculated_Rate'])\n",
    "inconsistent_rates = df[df['Rate_Diff'] > 0.01].shape[0]\n",
    "print(f\"Rows with inconsistent rate calculation: {inconsistent_rates}\")\n",
    "\n",
    "# Check CI consistency\n",
    "ci_inconsistent = df[(df['CI.lower'] > df['Rate']) | (df['CI.upper'] < df['Rate'])].shape[0]\n",
    "print(f\"Rows with CI bounds inconsistent with Rate: {ci_inconsistent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fb0c00-ae42-4cc8-bdd4-1f40dd7bbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. OUTLIER DETECTION\n",
      "==============================\n",
      "Count: 25242 outliers detected\n",
      "Population: 16425 outliers detected\n",
      "Rate: 29139 outliers detected\n"
     ]
    }
   ],
   "source": [
    "# 6. OUTLIER DETECTION\n",
    "print(\"\\n6. OUTLIER DETECTION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Using IQR method for numeric columns\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "numeric_columns = ['Count', 'Population', 'Rate']\n",
    "for col in numeric_columns:\n",
    "    outliers = detect_outliers_iqr(df, col)\n",
    "    print(f\"{col}: {len(outliers)} outliers detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8cbccc-859a-4dab-9d5e-cefe47cb4300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. SMALL POPULATION ANALYSIS\n",
      "==============================\n",
      "Rows with population < 1000: 1602\n",
      "Rows with zero count but positive rate: 0\n"
     ]
    }
   ],
   "source": [
    "# 7. HANDLING ZERO AND NEAR-ZERO POPULATIONS\n",
    "print(\"\\n7. SMALL POPULATION ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Check for very small populations\n",
    "small_pop = df[df['Population'] < 1000]\n",
    "print(f\"Rows with population < 1000: {len(small_pop)}\")\n",
    "\n",
    "# Check for zero counts with non-zero rates\n",
    "zero_count_issues = df[(df['Count'] == 0) & (df['Rate'] > 0)]\n",
    "print(f\"Rows with zero count but positive rate: {len(zero_count_issues)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed02cf4-b346-460e-b90c-17a8c3a1689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. UNSTABLE FLAG ANALYSIS\n",
      "==============================\n",
      "Unstable flag distribution:\n",
      "Unstable\n",
      "-    101036\n",
      "*     29012\n",
      "      11729\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Statistics for unstable records:\n",
      "            Population                    Count        \n",
      "                  mean  min       max      mean min max\n",
      "Unstable                                               \n",
      "*         1.300901e+06  533  38501494  4.092169   1  18\n",
      "-         3.657388e+05  533  38501494  0.000000   0   0\n"
     ]
    }
   ],
   "source": [
    "# 8. UNSTABLE FLAG ANALYSIS\n",
    "print(\"\\n8. UNSTABLE FLAG ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "print(\"Unstable flag distribution:\")\n",
    "print(df['Unstable'].value_counts(dropna=False))\n",
    "\n",
    "# Analyze characteristics of unstable records\n",
    "if 'Unstable' in df.columns:\n",
    "    unstable_stats = df[df['Unstable'].isin(['*', '-'])].groupby('Unstable').agg({\n",
    "        'Population': ['mean', 'min', 'max'],\n",
    "        'Count': ['mean', 'min', 'max']\n",
    "    })\n",
    "    print(\"\\nStatistics for unstable records:\")\n",
    "    print(unstable_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6d401d-61ef-4406-978b-8239ba4d3959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. DATA IMPUTATION STRATEGY\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 9. DATA IMPUTATION STRATEGIES\n",
    "print(\"\\n9. DATA IMPUTATION STRATEGY\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# For missing CI values, we can calculate them based on rate and population\n",
    "# Using normal approximation for rate CI\n",
    "def calculate_ci(row):\n",
    "    if pd.isna(row['CI.lower']) or pd.isna(row['CI.upper']):\n",
    "        rate = row['Rate'] / 100000  # Convert to rate per person\n",
    "        population = row['Population']\n",
    "        if population > 0 and rate > 0:\n",
    "            # Wilson score interval for proportion\n",
    "            z = 1.96  # 95% CI\n",
    "            n = population\n",
    "            p = rate\n",
    "            denominator = 1 + z**2 / n\n",
    "            centre_adjusted_probability = p + z**2 / (2 * n)\n",
    "            adjusted_standard_deviation = np.sqrt((p * (1 - p) + z**2 / (4 * n)) / n)\n",
    "            \n",
    "            lower_bound = (centre_adjusted_probability - z * adjusted_standard_deviation) / denominator\n",
    "            upper_bound = (centre_adjusted_probability + z * adjusted_standard_deviation) / denominator\n",
    "            \n",
    "            return lower_bound * 100000, upper_bound * 100000\n",
    "    return row['CI.lower'], row['CI.upper']\n",
    "\n",
    "# Apply CI calculation where needed\n",
    "ci_needs_calc = df[df['CI.lower'].isna() | df['CI.upper'].isna()].copy()\n",
    "if len(ci_needs_calc) > 0:\n",
    "    print(f\"Rows needing CI calculation: {len(ci_needs_calc)}\")\n",
    "    # This would be implemented based on statistical needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ffd09-1cad-49de-a85e-4e4a1d55cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. CREATE CLEANED DATASET\n",
    "print(\"\\n10. CREATING CLEANED DATASET\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Create a cleaned version\n",
    "cleaned_df = df.copy()\n",
    "\n",
    "# Handle missing values in categorical columns\n",
    "categorical_cols = ['Disease', 'County', 'Sex', 'Unstable']\n",
    "for col in categorical_cols:\n",
    "    if col in cleaned_df.columns:\n",
    "        if cleaned_df[col].isna().sum() > 0:\n",
    "            if col == 'Unstable':\n",
    "                cleaned_df[col] = cleaned_df[col].fillna('')\n",
    "            else:\n",
    "                # For other categoricals, use mode or specific value\n",
    "                mode_val = cleaned_df[col].mode()[0] if not cleaned_df[col].mode().empty else 'Unknown'\n",
    "                cleaned_df[col] = cleaned_df[col].fillna(mode_val)\n",
    "\n",
    "# Handle missing numeric values\n",
    "numeric_cols = ['Count', 'Population', 'Rate', 'CI.lower', 'CI.upper']\n",
    "for col in numeric_cols:\n",
    "    if cleaned_df[col].isna().sum() > 0:\n",
    "        # Use median for the specific county and year\n",
    "        cleaned_df[col] = cleaned_df.groupby(['County', 'Year'])[col].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        # If still NaN, use overall median\n",
    "        cleaned_df[col] = cleaned_df[col].fillna(cleaned_df[col].median())\n",
    "\n",
    "# Add derived columns\n",
    "cleaned_df['Year_Index'] = cleaned_df['Year'] - 2000  # Create year index starting from 1\n",
    "cleaned_df['Decade'] = (cleaned_df['Year'] // 10) * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27de74-79c5-4f7f-87bd-651f94d6c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. SAVE CLEANED DATASET\n",
    "print(\"\\n11. SAVING CLEANED DATASETS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Save main cleaned dataset\n",
    "cleaned_df.to_csv('cleaned_infectious_disease.csv', index=False)\n",
    "print(\"Saved: cleaned_infectious_disease.csv\")\n",
    "\n",
    "# Create and save aggregated datasets\n",
    "# County-level yearly totals (ignoring gender)\n",
    "county_yearly = cleaned_df[cleaned_df['Sex'] == 'Total'].copy()\n",
    "county_yearly.to_csv('county_yearly_totals.csv', index=False)\n",
    "print(\"Saved: county_yearly_totals.csv\")\n",
    "\n",
    "# State-level aggregates\n",
    "state_yearly = cleaned_df[cleaned_df['County'] == 'California'].copy()\n",
    "state_yearly.to_csv('california_state_totals.csv', index=False)\n",
    "print(\"Saved: california_state_totals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedbcf5-cde6-421c-9935-a80eea6a6748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e04fe-a49c-4dba-936a-1e0f84362bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7f3cb-1a9d-4186-8bda-ffe0f8b8dc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436367c7-b6a1-4911-a90f-6e2fb2958880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9758684-25d5-4ccc-8973-e1b844241c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3b6c3-277e-44ea-999d-0ad134c703b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072f007-5cb7-41de-8efe-f9c40a0c0910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c963880-314e-42ca-a857-c08676f74304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8005827-3385-4d60-a017-d9e1c41beb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92385718-bf18-4081-ac46-05e9177ca61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b21526-14eb-4ab6-84bd-fda23bdce224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f4aa8-5a46-4114-9e1a-533aec85bfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f991da2-52a5-4844-bce5-eac4a48cc724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
