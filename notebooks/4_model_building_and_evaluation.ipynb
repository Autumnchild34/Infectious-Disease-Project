{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e294c7-428e-4552-a033-c5ac3557efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL BUILDING AND EVALUATION\n",
      "==================================================\n",
      "\n",
      "1. LOADING TRAINED MODEL AND DATA\n",
      "==============================\n",
      "Loading default model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'feature_info.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m         best_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Load feature information\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_info.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     37\u001b[0m     feature_info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     39\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m feature_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'feature_info.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"MODEL BUILDING AND EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. LOAD TRAINED MODEL AND DATA\n",
    "print(\"\\n1. LOADING TRAINED MODEL AND DATA\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Load best model\n",
    "try:\n",
    "    best_model = joblib.load('best_model_random_forest.pkl')\n",
    "    print(\"Loaded: Random Forest model\")\n",
    "except:\n",
    "    try:\n",
    "        best_model = joblib.load('best_model_gradient_boosting.pkl')\n",
    "        print(\"Loaded: Gradient Boosting model\")\n",
    "    except:\n",
    "        print(\"Loading default model...\")\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        best_model = RandomForestRegressor()\n",
    "\n",
    "# Load feature information\n",
    "with open('feature_info.json', 'r') as f:\n",
    "    feature_info = json.load(f)\n",
    "\n",
    "selected_features = feature_info['selected_features']\n",
    "print(f\"Number of features: {len(selected_features)}\")\n",
    "\n",
    "# Load predictions\n",
    "predictions_df = pd.read_csv('test_predictions.csv')\n",
    "print(f\"Test predictions loaded: {predictions_df.shape[0]} samples\")\n",
    "\n",
    "# Load full dataset for analysis\n",
    "df = pd.read_csv('cleaned_infectious_disease.csv')\n",
    "df_total = df[df['Sex'] == 'Total'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35881ce-edf0-4d18-95b8-28e3b67c2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. HYPERPARAMETER OPTIMIZATION\n",
      "==============================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Use the same feature engineering as in training\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# (Recreating features for demonstration)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m features_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_total\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     14\u001b[0m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear_Since_2000\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m     15\u001b[0m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRate_Lag1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_total' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. HYPERPARAMETER OPTIMIZATION RESULTS\n",
    "print(\"\\n2. HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare data for hyperparameter tuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the same feature engineering as in training\n",
    "# (Recreating features for demonstration)\n",
    "features_df = df_total.copy()\n",
    "features_df['Year_Since_2000'] = features_df['Year'] - 2000\n",
    "features_df['Rate_Lag1'] = features_df.groupby('County')['Rate'].shift(1)\n",
    "features_df = features_df.dropna(subset=['Rate_Lag1'])\n",
    "\n",
    "# Create simplified feature set for demonstration\n",
    "X = features_df[['Year_Since_2000', 'Rate_Lag1']]\n",
    "y = features_df['Rate']\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=False\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(\"Performing Randomized Search for Random Forest...\")\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Use randomized search for efficiency\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of parameter settings sampled\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"Best cross-validation RMSE: {-random_search.best_score_:.4f}\")\n",
    "\n",
    "# Train with best parameters\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_val = best_rf.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "print(f\"Validation RMSE with optimized parameters: {val_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078b0b8-929f-453d-8a89-6f5cc8fa8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MODEL COMPARISON WITH STATISTICAL TESTS\n",
    "print(\"\\n3. MODEL COMPARISON WITH STATISTICAL TESTS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train comparison models\n",
    "models = {\n",
    "    'Random Forest': best_rf,\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Ridge Regression': Ridge(alpha=1.0)\n",
    "}\n",
    "\n",
    "# Store predictions for statistical tests\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    predictions[name] = pred\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    print(f\"{name:20s}: RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Diebold-Mariano test for comparing forecasts\n",
    "def diebold_mariano_test(y_true, pred1, pred2, h=1):\n",
    "    \"\"\"Diebold-Mariano test for predictive accuracy.\"\"\"\n",
    "    e1 = y_true - pred1\n",
    "    e2 = y_true - pred2\n",
    "    d = e1**2 - e2**2\n",
    "    \n",
    "    n = len(d)\n",
    "    dm_stat = np.mean(d) / np.sqrt(np.var(d) / n)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "# Compare Random Forest vs Gradient Boosting\n",
    "dm_stat, p_value = diebold_mariano_test(y_val, predictions['Random Forest'], \n",
    "                                        predictions['Gradient Boosting'])\n",
    "print(f\"\\nDiebold-Mariano Test (RF vs GB):\")\n",
    "print(f\"  DM Statistic: {dm_stat:.4f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Significant difference: {'Yes' if p_value < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b03d5b-0c60-474e-ac68-8b3d3920a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. PERFORMANCE METRICS ANALYSIS\n",
    "print(\"\\n4. DETAILED PERFORMANCE METRICS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculate comprehensive performance metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['MAE'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics['RMSE'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    metrics['R2'] = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Percentage errors\n",
    "    metrics['MAPE'] = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-10))) * 100\n",
    "    \n",
    "    # Symmetric MAPE\n",
    "    metrics['sMAPE'] = 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / \n",
    "                                               (np.abs(y_true) + np.abs(y_pred) + 1e-10))\n",
    "    \n",
    "    # Theil's U statistic\n",
    "    numerator = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    denominator = np.sqrt(np.mean(y_true**2)) + np.sqrt(np.mean(y_pred**2))\n",
    "    metrics['Theil_U'] = numerator / denominator\n",
    "    \n",
    "    # Directional accuracy\n",
    "    y_true_chg = np.diff(y_true) > 0\n",
    "    y_pred_chg = np.diff(y_pred) > 0\n",
    "    if len(y_true_chg) > 0:\n",
    "        metrics['DA'] = np.mean(y_true_chg == y_pred_chg)\n",
    "    else:\n",
    "        metrics['DA'] = np.nan\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric:10s}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for best model\n",
    "best_metrics = calculate_metrics(y_test, predictions_df['Predicted'].values, \n",
    "                                \"Best Model on Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65df6d-f8f2-427d-9585-5a096fd0060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. RESIDUAL DIAGNOSTICS\n",
    "print(\"\\n5. RESIDUAL ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = predictions_df['Actual'] - predictions_df['Predicted']\n",
    "\n",
    "# Create residual analysis plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Residual Diagnostics', fontsize=16)\n",
    "\n",
    "# 1. Residual distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "ax1.set_title('Distribution of Residuals')\n",
    "ax1.set_xlabel('Residual')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Q-Q plot\n",
    "ax2 = axes[0, 1]\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot of Residuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals vs Predicted\n",
    "ax3 = axes[0, 2]\n",
    "scatter = ax3.scatter(predictions_df['Predicted'], residuals, alpha=0.6)\n",
    "ax3.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "ax3.set_title('Residuals vs Predicted Values')\n",
    "ax3.set_xlabel('Predicted Rate')\n",
    "ax3.set_ylabel('Residual')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals vs Time (Year)\n",
    "ax4 = axes[1, 0]\n",
    "for county in predictions_df['County'].unique()[:5]:  # Top 5 counties\n",
    "    county_data = predictions_df[predictions_df['County'] == county]\n",
    "    ax4.scatter(county_data['Year'], county_data['Actual'] - county_data['Predicted'], \n",
    "               alpha=0.7, label=county, s=50)\n",
    "ax4.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "ax4.set_title('Residuals by Year (Top 5 Counties)')\n",
    "ax4.set_xlabel('Year')\n",
    "ax4.set_ylabel('Residual')\n",
    "ax4.legend(loc='best', fontsize=8)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Actual vs Predicted\n",
    "ax5 = axes[1, 1]\n",
    "ax5.scatter(predictions_df['Actual'], predictions_df['Predicted'], alpha=0.6)\n",
    "# Perfect prediction line\n",
    "min_val = min(predictions_df['Actual'].min(), predictions_df['Predicted'].min())\n",
    "max_val = max(predictions_df['Actual'].max(), predictions_df['Predicted'].max())\n",
    "ax5.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')\n",
    "ax5.set_title('Actual vs Predicted Values')\n",
    "ax5.set_xlabel('Actual Rate')\n",
    "ax5.set_ylabel('Predicted Rate')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Residual autocorrelation\n",
    "ax6 = axes[1, 2]\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(residuals, lags=10, ax=ax6, alpha=0.05)\n",
    "ax6.set_title('Autocorrelation of Residuals')\n",
    "ax6.set_xlabel('Lag')\n",
    "ax6.set_ylabel('Autocorrelation')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('residual_diagnostics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests on residuals\n",
    "print(\"\\nStatistical Tests on Residuals:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Shapiro-Wilk test for normality\n",
    "shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "print(f\"Shapiro-Wilk test for normality:\")\n",
    "print(f\"  Statistic: {shapiro_stat:.4f}\")\n",
    "print(f\"  p-value: {shapiro_p:.4e}\")\n",
    "print(f\"  Residuals are normal: {'Yes' if shapiro_p > 0.05 else 'No'}\")\n",
    "\n",
    "# Durbin-Watson test for autocorrelation\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"\\nDurbin-Watson test for autocorrelation:\")\n",
    "print(f\"  Statistic: {dw_stat:.4f}\")\n",
    "print(f\"  Interpretation: {'No autocorrelation' if 1.5 < dw_stat < 2.5 else 'Possible autocorrelation'}\")\n",
    "\n",
    "# Breusch-Pagan test for heteroscedasticity\n",
    "import statsmodels.api as sm\n",
    "X_with_const = sm.add_constant(predictions_df['Predicted'])\n",
    "model = sm.OLS(residuals**2, X_with_const).fit()\n",
    "bp_stat = model.nobs * model.rsquared\n",
    "bp_p = 1 - stats.chi2.cdf(bp_stat, 1)\n",
    "print(f\"\\nBreusch-Pagan test for heteroscedasticity:\")\n",
    "print(f\"  Statistic: {bp_stat:.4f}\")\n",
    "print(f\"  p-value: {bp_p:.4e}\")\n",
    "print(f\"  Homoscedastic: {'Yes' if bp_p > 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2be73-56b5-4e7a-9222-a762e9ae59f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19f444-e85f-4644-aa38-657bffdb3631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b34b3-78c2-4056-88c4-79c4c07784f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95669-ea1f-4149-85db-b3416640220e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636411a-31e5-401d-8b42-c854ed3ce307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036910ee-24a0-4077-bb47-fb8721bdeba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982d290-8557-47da-96f6-afa316c78ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee381d-3da5-4797-b71f-301a513742cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4aedf-26b1-487e-a187-d0285ddb6485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
