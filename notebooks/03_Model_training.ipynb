{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9813cc-6ae5-41a0-8f4c-2675da7336cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for modeling...\n",
      "Dataset shape: (141777, 14)\n",
      "Total records (excluding gender breakdown): 47259\n",
      "\n",
      " 1. PROBLEM FORMULATION\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWe will explore three modeling approaches:\\n\\n1. REGRESSION: Predict incidence rate (Rate) for each county-year combination\\n2. CLASSIFICATION: Predict high-risk counties (above median rate)\\n3. TIME SERIES: Forecast future incidence rates\\n\\nPrimary focus: Regression problem to predict incidence rates\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load cleaned data\n",
    "print(\"Loading data for modeling...\")\n",
    "df = pd.read_csv('cleaned_infectious_disease.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Filter for total population (not gender-specific)\n",
    "df_total = df[df['Sex'] == 'Total'].copy()\n",
    "print(f\"Total records (excluding gender breakdown): {df_total.shape[0]}\")\n",
    "\n",
    "# 1. PROBLEM FORMULATION\n",
    "print(\"\\n 1. PROBLEM FORMULATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "\"\"\"\n",
    "We will explore three modeling approaches:\n",
    "\n",
    "1. REGRESSION: Predict incidence rate (Rate) for each county-year combination\n",
    "2. CLASSIFICATION: Predict high-risk counties (above median rate)\n",
    "3. TIME SERIES: Forecast future incidence rates\n",
    "\n",
    "Primary focus: Regression problem to predict incidence rates\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d3cfa4-5569-47cf-9b67-8a978aca0238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. FEATURE ENGINEERING\n",
      "==============================\n",
      "Final dataset shape: (23856, 78)\n",
      "Feature columns: ['Year_Since_2000', 'Year_Squared', 'Population', 'Population_Percentile', 'Rate_Lag1', 'Rate_Lag2', 'Rate_Lag3', 'Rate_MA2', 'Rate_MA3', 'Rate_Change_Lag1', 'Rate_Pct_Change_Lag1', 'County_Rate_Mean', 'County_Rate_Std', 'Rate_Z_Score', 'Population_Year_Interaction', 'Rate_Lag1_Population', 'County_Alpine', 'County_Amador', 'County_Butte', 'County_Calaveras', 'County_California', 'County_Colusa', 'County_Contra Costa', 'County_Del Norte', 'County_El Dorado', 'County_Fresno', 'County_Glenn', 'County_Humboldt', 'County_Imperial', 'County_Inyo', 'County_Kern', 'County_Kings', 'County_Lake', 'County_Lassen', 'County_Los Angeles', 'County_Madera', 'County_Marin', 'County_Mariposa', 'County_Mendocino', 'County_Merced', 'County_Modoc', 'County_Mono', 'County_Monterey', 'County_Napa', 'County_Nevada', 'County_Orange', 'County_Placer', 'County_Plumas', 'County_Riverside', 'County_Sacramento', 'County_San Benito', 'County_San Bernardino', 'County_San Diego', 'County_San Francisco', 'County_San Joaquin', 'County_San Luis Obispo', 'County_San Mateo', 'County_Santa Barbara', 'County_Santa Clara', 'County_Santa Cruz', 'County_Shasta', 'County_Sierra', 'County_Siskiyou', 'County_Solano', 'County_Sonoma', 'County_Stanislaus', 'County_Sutter', 'County_Tehama', 'County_Trinity', 'County_Tulare', 'County_Tuolumne', 'County_Ventura', 'County_Yolo', 'County_Yuba', 'Cluster_0', 'Cluster_1', 'Cluster_2', 'Cluster_3']\n"
     ]
    }
   ],
   "source": [
    "# 2. FEATURE ENGINEERING\n",
    "print(\"\\n2. FEATURE ENGINEERING\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Create features at county-year level\n",
    "features_df = df_total.copy()\n",
    "\n",
    "# Basic temporal features\n",
    "features_df['Year_Since_2000'] = features_df['Year'] - 2000\n",
    "features_df['Year_Squared'] = features_df['Year_Since_2000'] ** 2\n",
    "\n",
    "# Lag features (previous year's rate)\n",
    "features_df = features_df.sort_values(['County', 'Year'])\n",
    "\n",
    "# Create lagged rate for each county\n",
    "features_df['Rate_Lag1'] = features_df.groupby('County')['Rate'].shift(1)\n",
    "features_df['Rate_Lag2'] = features_df.groupby('County')['Rate'].shift(2)\n",
    "features_df['Rate_Lag3'] = features_df.groupby('County')['Rate'].shift(3)\n",
    "\n",
    "# Moving averages\n",
    "features_df['Rate_MA2'] = features_df.groupby('County')['Rate'].rolling(window=2).mean().reset_index(level=0, drop=True)\n",
    "features_df['Rate_MA3'] = features_df.groupby('County')['Rate'].rolling(window=3).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Rate change features\n",
    "features_df['Rate_Change_Lag1'] = features_df['Rate'] - features_df['Rate_Lag1']\n",
    "features_df['Rate_Pct_Change_Lag1'] = (features_df['Rate_Change_Lag1'] / features_df['Rate_Lag1']) * 100\n",
    "\n",
    "# County-level statistics (using only past data to avoid data leakage)\n",
    "county_stats = features_df.groupby('County').agg({\n",
    "    'Rate': ['mean', 'std', 'min', 'max']\n",
    "}).round(3)\n",
    "county_stats.columns = ['County_Rate_Mean', 'County_Rate_Std', 'County_Rate_Min', 'County_Rate_Max']\n",
    "\n",
    "# Merge county statistics\n",
    "features_df = features_df.merge(county_stats, left_on='County', right_index=True, how='left')\n",
    "\n",
    "# Create rate z-score relative to county history\n",
    "features_df['Rate_Z_Score'] = (features_df['Rate'] - features_df['County_Rate_Mean']) / features_df['County_Rate_Std']\n",
    "\n",
    "# Population density proxy (if we had area data, we'd use actual density)\n",
    "# Using population percentiles instead\n",
    "population_percentiles = features_df['Population'].rank(pct=True)\n",
    "features_df['Population_Percentile'] = population_percentiles\n",
    "\n",
    "# Create interaction features\n",
    "features_df['Population_Year_Interaction'] = features_df['Population'] * features_df['Year_Since_2000']\n",
    "features_df['Rate_Lag1_Population'] = features_df['Rate_Lag1'] * features_df['Population']\n",
    "\n",
    "# Regional features (group counties by rate patterns)\n",
    "# First, identify county clusters from EDA\n",
    "from sklearn.cluster import KMeans\n",
    "county_features = county_stats.values\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "county_clusters = kmeans.fit_predict(county_features)\n",
    "county_cluster_map = dict(zip(county_stats.index, county_clusters))\n",
    "features_df['County_Cluster'] = features_df['County'].map(county_cluster_map)\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "county_dummies = pd.get_dummies(features_df['County'], prefix='County', drop_first=True)\n",
    "cluster_dummies = pd.get_dummies(features_df['County_Cluster'], prefix='Cluster')\n",
    "\n",
    "# Combine all features\n",
    "X_full = pd.concat([\n",
    "    features_df[[\n",
    "        'Year_Since_2000', 'Year_Squared', 'Population', 'Population_Percentile',\n",
    "        'Rate_Lag1', 'Rate_Lag2', 'Rate_Lag3', 'Rate_MA2', 'Rate_MA3',\n",
    "        'Rate_Change_Lag1', 'Rate_Pct_Change_Lag1',\n",
    "        'County_Rate_Mean', 'County_Rate_Std', 'Rate_Z_Score',\n",
    "        'Population_Year_Interaction', 'Rate_Lag1_Population'\n",
    "    ]],\n",
    "    county_dummies,\n",
    "    cluster_dummies\n",
    "], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = features_df['Rate']\n",
    "\n",
    "# Remove rows with missing values (from lag features)\n",
    "valid_mask = ~X_full.isnull().any(axis=1) & ~y.isnull()\n",
    "X_full = X_full[valid_mask]\n",
    "y = y[valid_mask]\n",
    "features_df = features_df[valid_mask]\n",
    "\n",
    "print(f\"Final dataset shape: {X_full.shape}\")\n",
    "print(f\"Feature columns: {list(X_full.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7262fcc6-83a7-461f-a50e-804d3a732486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. FEATURE SELECTION\n",
      "==============================\n",
      "Top 10 features by absolute correlation:\n",
      "Rate_Z_Score            0.898879\n",
      "Rate_Change_Lag1        0.707160\n",
      "Rate_MA2                0.707052\n",
      "Rate_MA3                0.667718\n",
      "County_Rate_Mean        0.050621\n",
      "Cluster_3               0.049963\n",
      "County_Rate_Std         0.047817\n",
      "County_San Francisco    0.037481\n",
      "County_Alpine           0.035517\n",
      "County_Kern             0.031082\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Method 2: SelectKBest using f_regression\u001b[39;00m\n\u001b[0;32m     21\u001b[0m selector_kbest \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_regression, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m X_kbest \u001b[38;5;241m=\u001b[39m \u001b[43mselector_kbest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m selected_features_kbest \u001b[38;5;241m=\u001b[39m X_temp\u001b[38;5;241m.\u001b[39mcolumns[selector_kbest\u001b[38;5;241m.\u001b[39mget_support()]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSelected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(selected_features_kbest)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features using SelectKBest:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:921\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:561\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    559\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 561\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[0;32m    566\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION\n",
    "print(\"\\n3. FEATURE SELECTION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split data for feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Method 1: Correlation with target\n",
    "correlations = X_temp.corrwith(y_temp).abs().sort_values(ascending=False)\n",
    "print(\"Top 10 features by absolute correlation:\")\n",
    "print(correlations.head(10))\n",
    "\n",
    "# Method 2: SelectKBest using f_regression\n",
    "selector_kbest = SelectKBest(score_func=f_regression, k=20)\n",
    "X_kbest = selector_kbest.fit_transform(X_temp, y_temp)\n",
    "selected_features_kbest = X_temp.columns[selector_kbest.get_support()].tolist()\n",
    "print(f\"\\nSelected {len(selected_features_kbest)} features using SelectKBest:\")\n",
    "\n",
    "# Method 3: Recursive Feature Elimination\n",
    "estimator = LinearRegression()\n",
    "selector_rfe = RFE(estimator, n_features_to_select=15, step=1)\n",
    "selector_rfe.fit(X_temp, y_temp)\n",
    "selected_features_rfe = X_temp.columns[selector_rfe.get_support()].tolist()\n",
    "print(f\"\\nSelected {len(selected_features_rfe)} features using RFE:\")\n",
    "\n",
    "# Combine selection methods\n",
    "selected_features = list(set(selected_features_kbest[:15] + selected_features_rfe))\n",
    "print(f\"\\nTotal unique selected features: {len(selected_features)}\")\n",
    "print(\"Selected features:\")\n",
    "for i, feat in enumerate(sorted(selected_features), 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "# Use selected features\n",
    "X_selected = X_full[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1c221-8996-4c03-9779-7c6a234abba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TRAIN/VALIDATION/TEST SPLITS\n",
    "print(\"\\n4. DATA SPLITTING STRATEGY\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Time-based splitting (since this is time series data)\n",
    "# Use first 80% of years for training, next 10% for validation, last 10% for testing\n",
    "\n",
    "# Get unique years\n",
    "unique_years = sorted(features_df['Year'].unique())\n",
    "train_years = unique_years[:int(len(unique_years)*0.8)]  # 2001-2010\n",
    "val_years = unique_years[int(len(unique_years)*0.8):int(len(unique_years)*0.9)]  # 2011-2012\n",
    "test_years = unique_years[int(len(unique_years)*0.9):]  # 2013-2014\n",
    "\n",
    "print(f\"Training years: {train_years}\")\n",
    "print(f\"Validation years: {val_years}\")\n",
    "print(f\"Test years: {test_years}\")\n",
    "\n",
    "# Create masks\n",
    "train_mask = features_df['Year'].isin(train_years)\n",
    "val_mask = features_df['Year'].isin(val_years)\n",
    "test_mask = features_df['Year'].isin(test_years)\n",
    "\n",
    "# Split data\n",
    "X_train = X_selected[train_mask]\n",
    "X_val = X_selected[val_mask]\n",
    "X_test = X_selected[test_mask]\n",
    "\n",
    "y_train = y[train_mask]\n",
    "y_val = y[val_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "print(f\"\\nData split sizes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446acbf-e85c-448a-8c6b-eeb16ab6b707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca15d2b9-a40b-46ba-92ae-ca0c035af831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d759c5-881f-4f17-b632-e62833503a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f4a0-70d4-41f6-ac68-91b3335b83cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27ea6d-7ba2-496d-b6e7-5c0f5fc1666e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c0a3f-7d48-4c50-b45a-b4c9c3d8a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44976e9a-c417-4721-a264-3fcaa83abb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d426514-6404-4c76-b910-4198979104bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe512a9-ab19-4fd2-9250-f9f123738f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa1496-0fe1-4f7e-a438-f9340032ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
